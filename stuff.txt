import pandas as pd
import re
import matplotlib.pyplot as plt

def plot_file_date_distribution(file_list):
    # Create an empty DataFrame to store parsed data
    df = pd.DataFrame(columns=['File_Name', 'Group_Name', 'Datetime'])

    # Regular expression pattern to extract datetime and group name
    pattern = r'(TV.+Bin)_(\d{4}-\d{2}-\d{2}_\d{2}-\d{2}-\d{2})'

    # Iterate through each file name
    for file_name in file_list:
        # Extract group name and datetime using regex
        match = re.search(pattern, file_name)
        if match:
            group_name = match.group(1)
            datetime_str = match.group(2)

            # Append data to DataFrame
            df = df.append({'File_Name': file_name, 'Group_Name': group_name, 'Datetime': datetime_str}, ignore_index=True)

    # Convert 'Datetime' column to datetime format
    df['Datetime'] = pd.to_datetime(df['Datetime'], format='%Y-%m-%d_%H-%M-%S')

    # Bin the datetimes into groups of 10 minutes
    df['Binned_Datetime'] = df['Datetime'].dt.floor('10min')

    # Plot distribution for each unique group
    unique_groups = df['Group_Name'].unique()
    for group_name in unique_groups:
        group_df = df[df['Group_Name'] == group_name]
        plt.hist(group_df['Binned_Datetime'], bins=pd.date_range(start=group_df['Binned_Datetime'].min(), end=group_df['Binned_Datetime'].max(), freq='10min'), alpha=0.5, label=group_name)

    plt.xlabel('Time')
    plt.ylabel('Frequency')
    plt.title('File Date Distribution')
    plt.legend()
    plt.show()

# Example usage
file_list = [
    'TV404C PC2 ROM Bin North West_urn-uuid-00075fbe-4138-3841-be5f-0700075fbe5f_2024-05-04_23-41-50(1)_0000000.jpg',
    # Add more file names here
]
plot_file_date_distribution(file_list)



import boto3
from urllib.parse import urlparse

# Assuming you have already initialized your S3 client
s3 = boto3.client('s3')

uri = 's3://dev-iroccvdmsstack-dmsbucketb119a736-rtlxxvez6thx/frames/TV401C PC1 ROM Bin_urn-uuid-00075fbe-43fb-fb43-be5f-0700075fbe5f_2024-05-02_08-00-00(3)/'
parsed_uri = urlparse(uri)

prefix_frames22 = []

# Extract bucket name and object key prefix from the parsed URI
bucket_name = parsed_uri.netloc
prefix = parsed_uri.path.lstrip('/')

# Paginate through the results to retrieve all objects
paginator = s3.get_paginator('list_objects_v2')
pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)

for page in pages:
    object_keys = [obj['Key'] for obj in page.get('Contents', [])]
    prefix_frames22.extend(object_keys)

print(len(prefix_frames22))

